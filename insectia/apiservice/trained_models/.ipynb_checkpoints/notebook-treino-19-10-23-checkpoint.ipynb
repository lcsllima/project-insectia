{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nosso modelo é feito com o torch\n",
    "# Usaremos algumas classes de insetos (cada classe é uma subpasta de \"model_classes\", contendo fotos do inseto)\n",
    "# Só precisamos treinar o modelo para entender e classificar cada inseto quanto tiver uma foto dele\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.2316\n",
      "Epoch [2/10], Loss: 2.2139\n",
      "Epoch [3/10], Loss: 1.2695\n",
      "Epoch [4/10], Loss: 0.8500\n",
      "Epoch [5/10], Loss: 0.7845\n",
      "Epoch [6/10], Loss: 2.0272\n",
      "Epoch [7/10], Loss: 1.0856\n",
      "Epoch [8/10], Loss: 1.1176\n",
      "Epoch [9/10], Loss: 0.7586\n",
      "Epoch [10/10], Loss: 0.1379\n"
     ]
    }
   ],
   "source": [
    "# Primeiro preparamos os dados\n",
    "data_dir = 'model_classes' \n",
    "# data_dir = './model_classes' # Pasta model_classes, no caso, está na pasta que contém a subpasta do notebook\n",
    "num_classes = 5\n",
    "\n",
    "\n",
    "batch_size = 16 # Número de imagens que serão processadas por vez (quanto maior, mais memória é usada)\n",
    "num_epochs = 10 # Número de vezes que o modelo vai ver todas as imagens de treino, quanto maior melhor mas pode gerar overfitting\n",
    "\n",
    "# Transformações que serão aplicadas nas imagens\n",
    "# Primeiro convertemos a imagem para um tensor (um array multidimensional)\n",
    "# Depois normalizamos os valores dos pixels para que fiquem entre -1 e 1\n",
    "# Por fim, redimensionamos a imagem para 224x224 (tamanho padrão para o modelo)\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5]),\n",
    "    transforms.Resize((224, 224))\n",
    "])\n",
    "\n",
    "# Carregamos as imagens de treino e teste\n",
    "train_dataset = torchvision.datasets.ImageFolder(root=data_dir+'/train', transform=transform)\n",
    "test_dataset = torchvision.datasets.ImageFolder(root=data_dir+'/test', transform=transform)\n",
    "\n",
    "# Criamos um iterador para as imagens de treino e teste\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "# Agora criamos o modelo\n",
    "# Usaremos a arquitetura ResNet-18, que é um modelo pré-treinado\n",
    "# Isso significa que ele já foi treinado com milhões de imagens para reconhecer objetos\n",
    "# E nós vamos usar esse modelo para reconhecer insetos\n",
    "# Por isso, precisamos congelar os parâmetros do modelo, para que ele não seja treinado novamente\n",
    "# E vamos adicionar uma camada linear no final, para que ele reconheça insetos\n",
    "model = torchvision.models.resnet18(weights=True)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "model.fc = nn.Linear(512, num_classes)\n",
    "\n",
    "# Agora criamos a função de perda (loss) e o otimizador\n",
    "# Usaremos a função de perda Cross Entropy Loss\n",
    "# E o otimizador Adam (é um dos melhores)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.fc.parameters())\n",
    "\n",
    "\n",
    "# Primeiro definimos o dispositivo que será usado (GPU ou CPU), eu usarei uma GPU pois é disponível em meu computador\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Salvaremos o modelo na raiz do arquivo do notebook\n",
    "model_path = 'model_2.pth'\n",
    "\n",
    "# Agora treinamos o modelo\n",
    "model.to(device)\n",
    "for epoch in range(num_epochs):\n",
    "    for images, labels in train_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, loss.item()))\n",
    "\n",
    "# Salvamos o modelo\n",
    "torch.save(model.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A Acurácia do modelo com as imagens de testes é: 88.92921960072596 %\n"
     ]
    }
   ],
   "source": [
    "# agora verificamos a acuracia do modelo\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted==labels).sum().item()\n",
    "    \n",
    "    print('A Acurácia do modelo com as imagens de testes é: {} %'.format(100 * correct / total))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
